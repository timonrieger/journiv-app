# Journiv Production Docker Compose (SQLite).
# Journiv recommends using PostgreSQL based deployment instead.
# However, SQLite is still supported if you want to use it.
#
# Usage:
#   docker compose -f docker-compose.sqlite.yml up -d
#
# Required Environment Variables:
#   SECRET_KEY  - Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
#   DOMAIN_NAME - Needed when running in same-origin SPA mode (ENABLE_CORS=false)

x-common-valkey-env: &common-valkey-env
  REDIS_URL: redis://valkey:6379/0
  CELERY_BROKER_URL: redis://valkey:6379/0
  CELERY_RESULT_BACKEND: redis://valkey:6379/0

x-celery-common: &celery-common
  image: swalabtech/journiv-app:${APP_VERSION:-latest}
  env_file: .env
  volumes:
    - app_data:/data
  depends_on:
    valkey:
      condition: service_healthy
  networks:
    - backend
  restart: unless-stopped
  logging:
    driver: "json-file"
    options:
      max-size: "50m"
      max-file: "5"
  deploy:
    resources:
      limits:
        cpus: "1.0"
        memory: 1g
      reservations:
        memory: 256m

x-app-common: &app-common
  image: swalabtech/journiv-app:${APP_VERSION:-latest}
  env_file: .env
  volumes:
    - app_data:/data
  depends_on:
    valkey:
      condition: service_healthy
  networks:
    - backend
  restart: unless-stopped
  logging:
    driver: "json-file"
    options:
      max-size: "50m"
      max-file: "5"

x-celery-healthcheck: &celery-healthcheck
  interval: 30s
  timeout: 10s
  retries: 5
  start_period: 40s

services:
  # Journiv uses Valkey which is similar to Redis for cache.
  valkey:
    image: valkey/valkey:8.0-alpine
    container_name: journiv-valkey-cache
    restart: unless-stopped
    volumes:
      - valkey_data:/data
    networks:
      - backend
    healthcheck:
      test: ["CMD", "valkey-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  celery-worker:
    <<: *celery-common
    container_name: journiv-celery-worker
    command: celery -A app.core.celery_app worker --loglevel=info
    environment:
      <<: *common-valkey-env
      SERVICE_ROLE: celery-worker
      ENVIRONMENT: production
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "celery -A app.core.celery_app inspect ping --timeout=5 | grep -q pong",
        ]
      <<: *celery-healthcheck

  celery-beat:
    <<: *celery-common
    container_name: journiv-celery-beat
    command: celery -A app.core.celery_app beat --loglevel=info --scheduler redbeat.RedBeatScheduler
    environment:
      <<: *common-valkey-env
      SERVICE_ROLE: celery-beat
      ENVIRONMENT: production
      REDBEAT_REDIS_URL: redis://valkey:6379/2
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f 'celery.*beat' > /dev/null || exit 1"]
      <<: *celery-healthcheck

  app:
    <<: *app-common
    container_name: journiv-sqlite-app
    ports:
      - "${APP_PORT:-8000}:8000"
    environment:
      <<: *common-valkey-env
      SERVICE_ROLE: app
      ENVIRONMENT: production
      RATE_LIMIT_STORAGE_URI: redis://valkey:6379/1
    networks:
      - backend
      - frontend
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 2g
        reservations:
          memory: 512m

volumes:
  app_data:
  valkey_data:

networks:
  backend:
    driver: bridge
  frontend:
    driver: bridge
